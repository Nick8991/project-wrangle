
# Project Wrangle
This project consist of using data exploration techniques (web scaping) and tools (pandas, matplotlib, numpy and seaborn)  to wrangle and analyze data, provided by [udacity](https://learn.udacity.com/nanodegrees/nd002-alg-t2-fr/parts/27a1ae3a-cd53-41d8-8846-5da0b47af684/lessons/f9dc10d7-fb92-4a1b-9abd-2191b526d4b2/concepts/094a93ba-be03-4445-b315-8d488753063d).
The goal of the project to collect, clean and analyze data from twitter api
## Installations
- Download and install anaconda(cliick [here](https://repo.anaconda.com/archive/Anaconda3-2022.10-Windows-x86_64.exe) to download).
- create and manage a virtual environment for this project on windows.
- - `conda create -n env_name python`
- - `source activate env_name`
- `conda install pandas`
- `conda install matplotlib`
- `conda install numpy`
- ` conda install seaborn`
## Getting Started
- launch jupyter notebook in terminal : `jupyter notebook`
- create a twitter developer's account and send a request to twitter to twitter asking to use thier api  to collect data from [dog_rates](https://twitter.com/dog_rates?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor). This might take some time, usually up till a week before you are granted access.  
- Note: The data file needed to run this project from twitter is available and the code will work just fine except for the api access section as keys provided by twitter to access thier api are needed for the code to work.